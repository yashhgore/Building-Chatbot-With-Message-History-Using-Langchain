{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5379658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # Load environment variables from a .env file if present\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "507e7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f8bcc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Yash, it's nice to meet you! üòä\\n\\nIs there anything I can help you with today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 15, 'total_tokens': 41, 'completion_time': 0.047272727, 'prompt_time': 0.00125728, 'queue_time': 0.25219033, 'total_time': 0.048530007}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--b76f8234-3dad-47da-a760-84207a99b6d0-0', usage_metadata={'input_tokens': 15, 'output_tokens': 26, 'total_tokens': 41})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "ans=model.invoke([HumanMessage(content=\"Hii, My name is Yash\")])\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be98f8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You told me your name is Yash! üòä \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 53, 'total_tokens': 77, 'completion_time': 0.043636364, 'prompt_time': 0.00170799, 'queue_time': 0.25320953, 'total_time': 0.045344354}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--38720821-fa21-4d99-a112-ee9fa57ad1e5-0', usage_metadata={'input_tokens': 53, 'output_tokens': 24, 'total_tokens': 77})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hii, My name is Yash\"),\n",
    "    AIMessage(content=\"Hello Yash! It's nice to meet you. üëã\\n\\nWhat can I do for you today?\\n\"),\n",
    "    HumanMessage(content=\"can you tell my name?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8ae19",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3c8bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80f16809",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90a14bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My name is Yash and I am a software developer.\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c773d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Yash, it's nice to meet you!  \\n\\nI'm a large language model, here to help with any questions or tasks you might have. Since you're a software developer, is there anything specific I can assist you with today? Perhaps you need help brainstorming ideas, understanding a coding concept, or even just want to chat about the latest tech trends.  \\n\\nLet me know how I can be of service! üòä\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1422c944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Yash, as you told me at the beginning of our conversation. üòÑ  \\n\\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 128, 'total_tokens': 160, 'completion_time': 0.058181818, 'prompt_time': 0.003519049, 'queue_time': 0.25026396, 'total_time': 0.061700867}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a268fd99-8a93-4100-9359-57d89ee3c50c-0', usage_metadata={'input_tokens': 128, 'output_tokens': 32, 'total_tokens': 160})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69611bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to know! üòä\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config-->session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90a952b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi John! It's nice to meet you.  \\n\\nWhat can I do for you today?\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is John\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a33d213f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is John!  \\n\\nI remember that from our last conversation. üòä  Is there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac7d9b1",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4a21592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\" You are a helpful assistant that helps people find information.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e141995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Yash! üëã \\n\\nIt's nice to meet you.  \\n\\nWhat can I help you find information about today? üòä \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 26, 'total_tokens': 58, 'completion_time': 0.058181818, 'prompt_time': 0.00140075, 'queue_time': 0.246009919, 'total_time': 0.059582568}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d7b37bd6-afc9-4f61-9608-3c1c8d6652cf-0', usage_metadata={'input_tokens': 26, 'output_tokens': 32, 'total_tokens': 58})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hii, My name is Yash\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "732c7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e1ef902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Yash!\\n\\nI'm glad to meet you.  \\n\\nWhat can I help you find today?  \\n\\nDo you have a specific question or topic in mind? I can search the web, provide summaries of topics, or even help you brainstorm ideas. Just let me know how I can be of assistance. üòä  \\n\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My name is Yash\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4fc73bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Yash!  \\n\\nI remember that from our introduction. üòÑ  \\n\\nIs there anything else I can help you with, Yash?\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name?\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84c84ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\" You are a helpful assistant that helps people find information in {language}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "669cc966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Yash! üëã  \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•Ç‡§Å‡•§ \\n\\n‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?  üòä \\n\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hii, My name is Yash\")],\n",
    "     \"language\":\"Hindi\"}\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e502200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Gen AI stands for **Generative Artificial Intelligence**. \\n\\nIt's a type of artificial intelligence that focuses on creating new content.  \\n\\nThink of it like this:\\n\\n* **Traditional AI** is good at recognizing patterns and making predictions based on existing data. For example, it can tell you what kind of weather to expect tomorrow based on historical weather patterns.\\n\\n* **Gen AI** takes it a step further. It learns from existing data but then uses that knowledge to generate brand new content. \\n\\n**Here are some examples of what Gen AI can do:**\\n\\n* **Write stories, poems, and articles:** \\n\\n* **Compose music and create art:**\\n* **Translate languages:**\\n* **Summarize text:**\\n* **Answer your questions in a comprehensive and informative way, even if they are open ended, challenging, or strange:** (like this one!)\\n\\nGen AI is a rapidly developing field with huge potential to change the way we create and interact with information.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 205, 'prompt_tokens': 27, 'total_tokens': 232, 'completion_time': 0.372727273, 'prompt_time': 0.00141127, 'queue_time': 0.246902719, 'total_time': 0.374138543}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b6bb185-be96-4671-abf4-504615bce334-0', usage_metadata={'input_tokens': 27, 'output_tokens': 205, 'total_tokens': 232})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What is Gen AI?\")],\"language\":\"English\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c1ec5",
   "metadata": {},
   "source": [
    "Let's now wrap this more complicated chain in a Message History class. This time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dfede503",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef0d87f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§Ø‡§∂! üëã \\n\\n‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å‡•§  ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡•á ‡§ï‡•Å‡§õ ‡§≠‡•Ä ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡§π‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§Æ‡§ø‡§≤‡•á‡•§ üòä\\n\\n‡§Ü‡§™ ‡§ï‡§ø‡§∏ ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? \\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"My name is Yash\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06f5f29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§Ø‡§∂ ‡§π‡•à‡•§ üòä  \\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Whats my name?\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3fe2a",
   "metadata": {},
   "source": [
    "### Managing the Conversation History\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6223f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24058b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
